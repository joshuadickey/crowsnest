{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2520dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associator\n",
    "# Find an association of the waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fadb34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "from collections import deque\n",
    "from math import ceil\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from tensorflow import keras as ks\n",
    "from obspy import UTCDateTime\n",
    "from dateutil import parser\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "# Import configuration paramaters for pipeline\n",
    "import pconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a43f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy as BCE\n",
    "from tensorflow.keras import backend as K\n",
    "def nzHaversine(ytrue, ypred):\n",
    "    observation = tf.stack([ytrue[:,:,0]*latRange + extents[0], ytrue[:,:,1]*lonRange + extents[2]],axis=2)*0.017453292519943295\n",
    "    prediction = tf.stack([ypred[:,:,0]*latRange + extents[0], ypred[:,:,1]*lonRange + extents[2]],axis=2)*0.017453292519943295\n",
    "    used = tf.reduce_sum(tf.cast(tf.greater(tf.reduce_sum(ytrue, axis=2),0), dtype=tf.float32), axis=1)\n",
    "    dlon_dlat = observation - prediction \n",
    "    v = dlon_dlat / 2\n",
    "    v = tf.sin(v)\n",
    "    v = v**2\n",
    "    a = v[:,:,1] + tf.cos(observation[:,:,1]) * tf.cos(prediction[:,:,1]) * v[:,:,0]\n",
    "    c = tf.sqrt(a)\n",
    "    c = 2*tf.math.asin(c)\n",
    "    c = c*6378.1\n",
    "    final = tf.reduce_sum((tf.reduce_sum(c, axis=1))/used)\n",
    "    final = final/tf.dtypes.cast(tf.shape(observation)[0], dtype= tf.float32)\n",
    "    return final\n",
    "\n",
    "def nzDepth(ytrue, ypred):\n",
    "    used = maxArrivals - tf.reduce_sum(tf.cast(tf.equal(ytrue,0), dtype=tf.float32), axis=1)\n",
    "    used = tf.where(tf.equal(used, 0.), 1., used)\n",
    "    diffs = abs(tf.squeeze(ypred)-ytrue)*extents[4]\n",
    "    diffs = tf.reduce_sum(tf.reduce_sum(diffs, axis=1)/used)\n",
    "    return diffs/tf.dtypes.cast(tf.shape(ytrue)[0], dtype= tf.float32)\n",
    "\n",
    "def nzTime(ytrue, ypred):\n",
    "    used = maxArrivals - tf.reduce_sum(tf.cast(tf.equal(ytrue,0), dtype=tf.float32), axis=1)\n",
    "    used = tf.where(tf.equal(used, 0.), 1., used)\n",
    "    diffs = abs(tf.squeeze(ypred)-ytrue)*timeNormalize\n",
    "    diffs = tf.reduce_sum(tf.reduce_sum(diffs, axis=1)/used)\n",
    "    return diffs/tf.dtypes.cast(tf.shape(ytrue)[0], dtype= tf.float32)\n",
    "    \n",
    "def nzMSE1(ytrue, ypred):\n",
    "    used = maxArrivals - tf.reduce_sum(tf.cast(tf.equal(ytrue,0), dtype=tf.float32), axis=1)\n",
    "    used = tf.where(tf.equal(used, 0.), 1., used)\n",
    "    return K.mean(tf.reduce_sum(K.square(tf.squeeze(ypred)-ytrue),axis=1)/used)\n",
    "\n",
    "def nzMSE2(ytrue, ypred):\n",
    "    used = tf.reduce_sum(tf.cast(tf.greater(tf.reduce_sum(ytrue, axis=-1),0), dtype=tf.float32), axis=1)\n",
    "    used = tf.where(tf.equal(used, 0.), 1., used)\n",
    "    return K.mean(tf.reduce_sum(K.square(ypred-ytrue),axis=[1,2])/used)\n",
    "\n",
    "def nzBCE(ytrue, ypred):\n",
    "    used = tf.reduce_sum(tf.cast(tf.greater(tf.reduce_sum(ytrue, axis=1),0), dtype=tf.float32), axis=1)\n",
    "    used = tf.where(tf.equal(used, 0.), 1., used)\n",
    "    return K.mean(tf.reduce_sum(BCE(ytrue, ypred),axis=1)/used)\n",
    "\n",
    "def nzAccuracy(ytrue, ypred):\n",
    "    m = matrixSize/(tf.reduce_sum(tf.cast(tf.greater(tf.reduce_sum(ytrue, axis=1),0), dtype=tf.float32), axis=1)**2)\n",
    "    acc = tf.reduce_sum(tf.cast(ytrue==tf.round(ypred), dtype=tf.float32),axis=(1,2))/matrixSize\n",
    "    return K.mean(acc*m - m + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa7400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042ac4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(pconf.model_folder, pconf.assoc_model)\n",
    "model = load_model(model_file, custom_objects={'nzBCE':nzBCE, 'nzMSE1':nzMSE1, 'nzMSE2':nzMSE2, 'nzAccuracy':nzAccuracy, 'nzHaversine':nzHaversine, 'nzDepth':nzDepth, 'nzTime':nzTime}, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec558b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app_name = 'assoc'\n",
    "napp = 'next'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "269054e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test up method\n",
    "@app.route('/')\n",
    "def apitest():\n",
    "    return f'{app_name} is working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d6cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = [22.0, 40.0, 33.0, 62.0, 50.0] #latMin, latMax, lonMin, lonMax; Normalizing factor for model--do not change\n",
    "latRange = abs(extents[1] - extents[0])\n",
    "lonRange = abs(extents[3] - extents[2])\n",
    "outFile = \"assocOut.csv\"\n",
    "maxArrivals = 50\n",
    "minArrivals = 3\n",
    "timeNormalize = 120 # Normalizing factor for model; do not change\n",
    "associationWindow = 300\n",
    "clusterStrength = 0.9\n",
    "phases = {'P': 0, 'Pg': 0, 'PcP': 0, 'Pb': 0, 'p': 0, 'pg': 0, 'pcp': 0, 'pb': 0,\n",
    "          'Pn': 1, 'pn': 1,\n",
    "          'S': 2, 'Sg': 2, 'ScP': 2, 'Lg': 2, 'Sb': 2, 's': 2, 'sg': 2, 'scp': 2, 'lg': 2,\n",
    "          'Sn': 3, 'sn': 3}\n",
    "\n",
    "# Build permutation lists and matrices to predict on\n",
    "def permute():\n",
    "    outerWindow = associationWindow\n",
    "    edgeWindow = outerWindow/5\n",
    "    numWindows = ceil((X[:,2].max() + edgeWindow*2) / edgeWindow)\n",
    "    innerWindows = deque()\n",
    "    X_perm = deque()\n",
    "    start = -edgeWindow\n",
    "    for window in range(numWindows):\n",
    "        end = start+outerWindow\n",
    "        windowArrivals = np.where((X[:,2] >= start) & (X[:,2] < end))[0]\n",
    "        start += edgeWindow\n",
    "        if len(windowArrivals) >= minArrivals:\n",
    "            X_perm.append(windowArrivals[:maxArrivals])\n",
    "            innerWindows.append(start)\n",
    "    X_test = np.zeros((len(X_perm),maxArrivals,5))\n",
    "    for i in range(len(X_perm)):\n",
    "        X_test[i,:len(X_perm[i])] = X[X_perm[i]]\n",
    "        X_test[i,:len(X_perm[i]),2] -= X_test[i,0,2]\n",
    "    X_test[:,:,2] /= timeNormalize\n",
    "    return X_perm, X_test, innerWindows\n",
    "\n",
    "def buildEvents(X_perm, X_test, Y_pred, innerWindows):\n",
    "    # Get clusters for predicted matrix at index i\n",
    "    def cluster(i):\n",
    "        valids = np.where(X_test[i][:,4])[0]\n",
    "        validPreds = Y_pred[0][i][valids,:len(valids)]\n",
    "        L = 1-((validPreds.T + validPreds)/2)\n",
    "        np.fill_diagonal(L,0)\n",
    "        return fcluster(ward(squareform(L)), clusterStrength, criterion='distance')\n",
    "\n",
    "    innerWindow = associationWindow * (3/5)\n",
    "    catalogue = pd.DataFrame(columns=labels.columns)\n",
    "    events = deque()\n",
    "    evid = 1\n",
    "    for window in range(len(X_perm)):\n",
    "        clusters = cluster(window)\n",
    "        for c in np.unique(clusters):\n",
    "            pseudoEventIdx = np.where(clusters == c)[0]\n",
    "            pseudoEvent = X_perm[window][pseudoEventIdx]\n",
    "            if len(pseudoEvent) >= minArrivals: #TODO remove this\n",
    "                event = X[pseudoEvent]\n",
    "                # check for containment within inner window\n",
    "                contained = (event[0,2] >= innerWindows[window]) & (event[-1,2] <= (innerWindows[window]+innerWindow))\n",
    "                if contained:\n",
    "                    candidate = labels.iloc[pseudoEvent].copy()\n",
    "                    candidate['LAT'] = np.median(Y_pred[1][window][pseudoEventIdx][:,0])*latRange+extents[0]\n",
    "                    candidate['LON'] = np.median(Y_pred[1][window][pseudoEventIdx][:,1])*lonRange+extents[2]\n",
    "                    candidate['DEPTH'] = np.median(Y_pred[2][window][pseudoEventIdx])*extents[4]\n",
    "                    candidate['ETIME'] = candidate.TIME.iloc[0]+(np.median(Y_pred[3][window][pseudoEventIdx])*timeNormalize)\n",
    "                    # check for existence in catalogue\n",
    "                    overlap = candidate.ARID.isin(catalogue.ARID).sum()\n",
    "                    if overlap == 0:\n",
    "                        print(\"\\rPromoting event \" + str(evid), end='')\n",
    "                        events.append(pseudoEvent)\n",
    "                        candidate.EVID = evid\n",
    "                        catalogue = catalogue.append(candidate)\n",
    "                        evid += 1\n",
    "                    elif len(pseudoEvent) > overlap:\n",
    "                        catalogue.drop(catalogue[catalogue.ARID.isin(candidate.ARID)].index, inplace=True)\n",
    "                        candidate.EVID = evid\n",
    "                        catalogue = catalogue.append(candidate)\n",
    "                        evid += 1\n",
    "    catalogue = catalogue.groupby('EVID').filter(lambda x: len(x) >= minArrivals)\n",
    "    print()\n",
    "    return events, catalogue\n",
    "\n",
    "def matrixLink(X, labels):\n",
    "    print(\"Creating permutations... \", end='')\n",
    "    X_perm, X_test, innerWindows = permute()\n",
    "    print(\"predicting... \", end='')\n",
    "    Y_pred = model.predict({\"phase\": X_test[:,:,3], \"numerical_features\": X_test[:,:,[0,1,2,4]]})\n",
    "    print(\"clustering and building events...\")\n",
    "    events, catalogue = buildEvents(X_perm, X_test, Y_pred, innerWindows)\n",
    "    return catalogue\n",
    "\n",
    "def processInput(inputs):\n",
    "    print(\"Reading input file... \", end='')\n",
    "    X = []\n",
    "    labels = []\n",
    "    for i, r in inputs.iterrows(): # I can do this better\n",
    "        phase = r.PHASE\n",
    "        time = UTCDateTime(r.TIME)\n",
    "        lat = abs((r.ST_LAT - extents[0]) / latRange)\n",
    "        lon = abs((r.ST_LON - extents[2]) / lonRange)\n",
    "        otime = time - UTCDateTime(0)\n",
    "        try:\n",
    "            arrival = [lat, lon, otime, phases[phase], 1]\n",
    "            X.append(arrival)\n",
    "            labels.append(r)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    X = np.array(X)\n",
    "    idx = np.argsort(X[:,2])\n",
    "    X = X[idx,:]\n",
    "    X[:,2] -= X[0,2]\n",
    "    labels = pd.DataFrame([labels[i] for i in idx])\n",
    "    print(\"%d arrivals found\" % len(labels))\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1d6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URI that process the received requests\n",
    "@app.route(f'/{app_name}', methods=['POST'])\n",
    "def process_request():\n",
    "    pdict = request.json\n",
    "    inFile = pdict['cat']\n",
    "    inputs = pd.read_csv(inFile, names=['ARID', 'PHASE', 'TIME', 'STA', 'ST_LAT', 'ST_LON']).drop_duplicates(['PHASE','TIME','STA']).sort_values(by=['TIME'])\n",
    "    inputs.loc[:,'TIME'] = inputs.TIME.apply(lambda x: UTCDateTime(parser.parse(x))-UTCDateTime(0))\n",
    "    inputs.loc[:,'ST_LAT'] = inputs.ST_LAT.apply(lambda x: float(x))\n",
    "    inputs.loc[:,'ST_LON'] = inputs.ST_LON.apply(lambda x: float(x))\n",
    "    inputs['EVID'] = -1\n",
    "\n",
    "    X, labels = processInput(inputs)\n",
    "    outputs = matrixLink(X, labels)\n",
    "    outputs.to_csv(pdict['events'])\n",
    "    print(\"{} events created\".format(outputs.EVID.nunique()))\n",
    "    print(outputs)\n",
    "    forward(pdict)\n",
    "    return ('', 204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9760a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file... 263 arrivals found\n",
      "Creating permutations... predicting... clustering and building events...\n",
      "Promoting event 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARID</th>\n",
       "      <th>PHASE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>STA</th>\n",
       "      <th>ST_LAT</th>\n",
       "      <th>ST_LON</th>\n",
       "      <th>EVID</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>ETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>346</td>\n",
       "      <td>sn</td>\n",
       "      <td>1.590970e+09</td>\n",
       "      <td>HLID</td>\n",
       "      <td>43.5625</td>\n",
       "      <td>-114.4138</td>\n",
       "      <td>1</td>\n",
       "      <td>33.655364</td>\n",
       "      <td>50.977186</td>\n",
       "      <td>14.255042</td>\n",
       "      <td>1.590970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>321</td>\n",
       "      <td>sn</td>\n",
       "      <td>1.590970e+09</td>\n",
       "      <td>DUG</td>\n",
       "      <td>40.1950</td>\n",
       "      <td>-112.8133</td>\n",
       "      <td>1</td>\n",
       "      <td>33.655364</td>\n",
       "      <td>50.977186</td>\n",
       "      <td>14.255042</td>\n",
       "      <td>1.590970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>338</td>\n",
       "      <td>pg</td>\n",
       "      <td>1.590970e+09</td>\n",
       "      <td>HLID</td>\n",
       "      <td>43.5625</td>\n",
       "      <td>-114.4138</td>\n",
       "      <td>1</td>\n",
       "      <td>33.655364</td>\n",
       "      <td>50.977186</td>\n",
       "      <td>14.255042</td>\n",
       "      <td>1.590970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>pn</td>\n",
       "      <td>1.590970e+09</td>\n",
       "      <td>BMO</td>\n",
       "      <td>44.8525</td>\n",
       "      <td>-117.3060</td>\n",
       "      <td>3</td>\n",
       "      <td>33.820355</td>\n",
       "      <td>50.923999</td>\n",
       "      <td>15.874024</td>\n",
       "      <td>1.590970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299</td>\n",
       "      <td>pg</td>\n",
       "      <td>1.590970e+09</td>\n",
       "      <td>BMO</td>\n",
       "      <td>44.8525</td>\n",
       "      <td>-117.3060</td>\n",
       "      <td>3</td>\n",
       "      <td>33.820355</td>\n",
       "      <td>50.923999</td>\n",
       "      <td>15.874024</td>\n",
       "      <td>1.590970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>139</td>\n",
       "      <td>pn</td>\n",
       "      <td>1.591146e+09</td>\n",
       "      <td>HLID</td>\n",
       "      <td>43.5625</td>\n",
       "      <td>-114.4138</td>\n",
       "      <td>48</td>\n",
       "      <td>33.906388</td>\n",
       "      <td>50.468015</td>\n",
       "      <td>16.751945</td>\n",
       "      <td>1.591146e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>217</td>\n",
       "      <td>sn</td>\n",
       "      <td>1.591146e+09</td>\n",
       "      <td>TPNV</td>\n",
       "      <td>36.9488</td>\n",
       "      <td>-116.2495</td>\n",
       "      <td>48</td>\n",
       "      <td>33.906388</td>\n",
       "      <td>50.468015</td>\n",
       "      <td>16.751945</td>\n",
       "      <td>1.591146e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>128</td>\n",
       "      <td>sn</td>\n",
       "      <td>1.591146e+09</td>\n",
       "      <td>HAWA</td>\n",
       "      <td>46.3925</td>\n",
       "      <td>-119.5326</td>\n",
       "      <td>49</td>\n",
       "      <td>33.909687</td>\n",
       "      <td>50.585472</td>\n",
       "      <td>18.900292</td>\n",
       "      <td>1.591146e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>205</td>\n",
       "      <td>pn</td>\n",
       "      <td>1.591146e+09</td>\n",
       "      <td>TPNV</td>\n",
       "      <td>36.9488</td>\n",
       "      <td>-116.2495</td>\n",
       "      <td>49</td>\n",
       "      <td>33.909687</td>\n",
       "      <td>50.585472</td>\n",
       "      <td>18.900292</td>\n",
       "      <td>1.591146e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>212</td>\n",
       "      <td>pg</td>\n",
       "      <td>1.591146e+09</td>\n",
       "      <td>TPNV</td>\n",
       "      <td>36.9488</td>\n",
       "      <td>-116.2495</td>\n",
       "      <td>49</td>\n",
       "      <td>33.909687</td>\n",
       "      <td>50.585472</td>\n",
       "      <td>18.900292</td>\n",
       "      <td>1.591146e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ARID PHASE          TIME   STA   ST_LAT    ST_LON EVID        LAT  \\\n",
       "64   346    sn  1.590970e+09  HLID  43.5625 -114.4138    1  33.655364   \n",
       "41   321    sn  1.590970e+09   DUG  40.1950 -112.8133    1  33.655364   \n",
       "66   338    pg  1.590970e+09  HLID  43.5625 -114.4138    1  33.655364   \n",
       "1    297    pn  1.590970e+09   BMO  44.8525 -117.3060    3  33.820355   \n",
       "2    299    pg  1.590970e+09   BMO  44.8525 -117.3060    3  33.820355   \n",
       "..   ...   ...           ...   ...      ...       ...  ...        ...   \n",
       "151  139    pn  1.591146e+09  HLID  43.5625 -114.4138   48  33.906388   \n",
       "248  217    sn  1.591146e+09  TPNV  36.9488 -116.2495   48  33.906388   \n",
       "63   128    sn  1.591146e+09  HAWA  46.3925 -119.5326   49  33.909687   \n",
       "250  205    pn  1.591146e+09  TPNV  36.9488 -116.2495   49  33.909687   \n",
       "251  212    pg  1.591146e+09  TPNV  36.9488 -116.2495   49  33.909687   \n",
       "\n",
       "           LON      DEPTH         ETIME  \n",
       "64   50.977186  14.255042  1.590970e+09  \n",
       "41   50.977186  14.255042  1.590970e+09  \n",
       "66   50.977186  14.255042  1.590970e+09  \n",
       "1    50.923999  15.874024  1.590970e+09  \n",
       "2    50.923999  15.874024  1.590970e+09  \n",
       "..         ...        ...           ...  \n",
       "151  50.468015  16.751945  1.591146e+09  \n",
       "248  50.468015  16.751945  1.591146e+09  \n",
       "63   50.585472  18.900292  1.591146e+09  \n",
       "250  50.585472  18.900292  1.591146e+09  \n",
       "251  50.585472  18.900292  1.591146e+09  \n",
       "\n",
       "[118 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('clean_catalog.csv', names=['ARID', 'PHASE', 'TIME', 'STA', 'ST_LAT', 'ST_LON'])[1:].drop_duplicates(['PHASE','TIME','STA']).sort_values(by=['TIME'])\n",
    "test.loc[:,'TIME'] = test.TIME.apply(lambda x: UTCDateTime(parser.parse(x))-UTCDateTime(0))\n",
    "test.loc[:,'ST_LAT'] = test.ST_LAT.apply(lambda x: float(x))\n",
    "test.loc[:,'ST_LON'] = test.ST_LON.apply(lambda x: float(x))\n",
    "test['EVID'] = -1\n",
    "X, labels = processInput(test)\n",
    "outputs = matrixLink(X, labels)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787d5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(json_data):\n",
    "    response = requests.post(f'http://{pconf.host}:{pconf.apps[napp]}/{napp}', json = json_data, headers = pconf.head)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc350be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:6005/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(pconf.host, debug=False, port=pconf.apps[app_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab067c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
