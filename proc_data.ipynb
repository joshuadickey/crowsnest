{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68dfd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proc Data\n",
    "# app to prepare the data and send it to the picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65be515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.signal import lfilter, butter, decimate, hann, find_peaks\n",
    "\n",
    "from flask import Flask, request, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e3d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration paramaters for pipeline\n",
    "import pconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5c36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ded8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# App variables\n",
    "app = Flask(__name__)\n",
    "app_name = 'proc_data'\n",
    "napp = 'picker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4424d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters and stuff\n",
    "def DAT_normalize(X):\n",
    "    X = X - np.expand_dims(np.mean(X,1),1)\n",
    "    X = X / np.expand_dims(np.expand_dims(np.abs(X).max(1).max(1), 1), 1)\n",
    "    return X\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=8):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def DAT_filter(X, pdict, order=3):\n",
    "    lowcut = pdict['f_low']\n",
    "    highcut = pdict['f_hig']\n",
    "    fs = pdict['r_smp']\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return lfilter(b, a, X, axis=1) \n",
    "\n",
    "def DAT_taper(X, taper_percentage=.05):\n",
    "    npts = X.shape[1]\n",
    "    taper_len = int(npts * taper_percentage)\n",
    "    taper_sides = hann(2 * taper_len + 1)\n",
    "    taper = np.hstack((taper_sides[:taper_len], np.ones(npts - taper_len)))\n",
    "    return X * np.reshape(taper,(1,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a10aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mseed(full_path, pdict):\n",
    "    # Read the trace and return it with zeros on any gaps\n",
    "    # The data is also returned resampled to the r_smp rate\n",
    "    return obspy.read(full_path).merge(fill_value = 0).resample(pdict['r_smp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107ccec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read streams\n",
    "def read_streams(pdict):\n",
    "    streams = []\n",
    "    for f in pdict['files']:\n",
    "        streams.append(read_mseed(f['data_file'], pdict))\n",
    "    return streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8b70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(pdict):\n",
    "    streams = read_streams(pdict)\n",
    "    try:\n",
    "        wnum = 0\n",
    "        while True:\n",
    "            batch = {}\n",
    "            batch['X'] = []\n",
    "            batch['metadata'] = []\n",
    "            batch['window_size'] = pdict['window_size']\n",
    "            batch['dt'] = pdict['dt']\n",
    "            batch['c_len'] = pdict['c_len']\n",
    "            batch['r_smp'] = pdict['r_smp']\n",
    "            batch['cat'] = pdict['cat']\n",
    "            batch['trim'] = pdict['trim']\n",
    "            batch['clean_cat'] = pdict['clean_cat']\n",
    "            batch['events'] = pdict['events']\n",
    "            for i, stream in enumerate(streams):\n",
    "                start = obspy.UTCDateTime(stream[0].stats.starttime + (wnum * (pdict['window_size']-pdict['overlap'])))\n",
    "                end = obspy.UTCDateTime(start + pdict['window_size'])\n",
    "                # If there isnt enough data to form another cut it short\n",
    "#                 if (end > obspy.UTCDateTime(stream[0].stats.endtime)):\n",
    "#                     end = obspy.UTCDateTime(stream[0].stats.endtime)\n",
    "                st = stream.slice(starttime=start, endtime=end)\n",
    "                # Append the three channels stack to the data array\n",
    "                batch['X'].append(np.vstack((st[0].data, st[1].data, st[2].data)).T)\n",
    "                metadata = {\n",
    "                    'sta': pdict['files'][i]['sta'],\n",
    "                    'st_lat': pdict['files'][i]['st_lat'],\n",
    "                    'st_lon': pdict['files'][i]['st_lon'],\n",
    "                    'start': str(start),\n",
    "                }\n",
    "                batch['metadata'].append(metadata)\n",
    "            batch['X'] = DAT_normalize(DAT_taper(DAT_filter(batch['X'], pdict))).tolist()\n",
    "            wnum += 1\n",
    "            yield batch\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a709647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test up method\n",
    "@app.route('/')\n",
    "def apitest():\n",
    "    return f'{app_name} is working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845b7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URI that process the received requests\n",
    "@app.route(f'/{app_name}', methods=['POST'])\n",
    "def process_request():\n",
    "    # Exract json from request (received)\n",
    "    pdict = request.json\n",
    "    streams = read_streams(pdict)\n",
    "    for stream in streams:\n",
    "        print(stream)\n",
    "    gen = gen_data(pdict) \n",
    "    for i in range(pdict['n_windows']):\n",
    "        b = next(gen)\n",
    "        # Note that only the last response is saved and returned\n",
    "        picker_response = forward(b)\n",
    "    \n",
    "    # Return the response of processing the last batch.\n",
    "    return picker_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82023a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(json_data):\n",
    "    response = requests.post(f'http://{pconf.host}:{pconf.apps[napp]}/{napp}', json = json_data, headers = pconf.head)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fa526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:6002/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "US.BMO.00.BH1 | 2020-06-01T00:00:00.000001Z - 2020-06-01T23:59:59.950001Z | 20.0 Hz, 1728000 samples\n",
      "US.BMO.00.BH2 | 2020-06-01T00:00:00.000001Z - 2020-06-01T23:59:59.950001Z | 20.0 Hz, 1728000 samples\n",
      "US.BMO.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.BOZ.00.BH1 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.BOZ.00.BH2 | 2020-06-01T00:00:00.024998Z - 2020-06-01T23:59:59.974998Z | 20.0 Hz, 1728000 samples\n",
      "US.BOZ.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.DUG.00.BH1 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.DUG.00.BH2 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.DUG.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.HAWA.00.BH1 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.HAWA.00.BH2 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.HAWA.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Nov/2021 22:59:27] \"\u001b[37mPOST /proc_data HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "US.BMO.00.BH1 | 2020-06-01T00:00:00.000001Z - 2020-06-01T23:59:59.950001Z | 20.0 Hz, 1728000 samples\n",
      "US.BMO.00.BH2 | 2020-06-01T00:00:00.000001Z - 2020-06-01T23:59:59.950001Z | 20.0 Hz, 1728000 samples\n",
      "US.BMO.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.BOZ.00.BH1 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.BOZ.00.BH2 | 2020-06-01T00:00:00.024998Z - 2020-06-01T23:59:59.974998Z | 20.0 Hz, 1728000 samples\n",
      "US.BOZ.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.DUG.00.BH1 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.DUG.00.BH2 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.DUG.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.HAWA.00.BH1 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.HAWA.00.BH2 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.HAWA.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "3 Trace(s) in Stream:\n",
      "US.HLID.00.BH1 | 2020-06-01T00:00:00.000001Z - 2020-06-01T23:59:59.950001Z | 20.0 Hz, 1728000 samples\n",
      "US.HLID.00.BH2 | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n",
      "US.HLID.00.BHZ | 2020-06-01T00:00:00.000000Z - 2020-06-01T23:59:59.950000Z | 20.0 Hz, 1728000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Nov/2021 23:04:02] \"\u001b[37mPOST /proc_data HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(pconf.host, debug=False, port=pconf.apps[app_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aefc44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
